{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/g.frigo/.pyenv/versions/3.11.1/envs/relu/lib/python3.11/site-packages/datasets/load.py:1429: FutureWarning: The repository for wikipedia contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/wikipedia\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9083e251e1c454b95f956a5f70808c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/35.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b5f139f56d0457f8b723eb197a125e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/16.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74db3575c6604fd4a807cbc82e02a7b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/15.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "615e7b57162e4f51a9e9da64aa96bbb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/20.3G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset('wikipedia', \"20220301.en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmap\n",
    "import os\n",
    "with open(\"test.db\", mode=\"a+\", encoding=\"utf-8\") as file_obj:\n",
    "    os.ftruncate(file_obj.fileno(), 2**30)\n",
    "\n",
    "#    with mmap.mmap(file_obj.fileno(), length=0, access=mmap.ACCESS_WRITE) as mmap_obj:\n",
    "#        mmap_obj.write(bytes(\"\".join([chr(i) for i in range(256)]),\"utf-8\"))\n",
    "#        mmap_obj.flush()\n",
    "#        print(mmap_obj.size())\n",
    "\n",
    "#def billy(s:mmap,pagesize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TextIO\n",
    "def read_chunk(file:TextIO,chunk_size:int=1024)->str:\n",
    "    while True:\n",
    "        str_chunk = file.read(chunk_size)\n",
    "        if not str_chunk:\n",
    "            break\n",
    "        yield str_chunk\n",
    "\n",
    "char_frequency={}\n",
    "with open(\"resources/shakespeare.txt\", mode=\"r\", encoding=\"utf-8\") as file_obj:\n",
    "    for str_chunk in read_chunk(file_obj):\n",
    "        for char in str_chunk:\n",
    "            if char in char_frequency:\n",
    "                char_frequency[char]+=1\n",
    "            else:\n",
    "                char_frequency[char]=1\n",
    "\n",
    "#itemize\n",
    "char=[]\n",
    "counts=[]\n",
    "for item,count in char_frequency.items():\n",
    "    char.append(item)\n",
    "    counts.append(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fR .redt weeen romt.lyhEng ;r\n",
      "\n",
      ".o oaezdeIra to,lyw\n",
      "o,lndnh\n",
      "uafwhnft henuwgmrIP,SnRss on\n",
      "r uc eu nea\n",
      ",oTRheAeieyr. hse Ed i ,s \n",
      "s, ucN os t se Athdg\n",
      "weiretTt ihs.aiold iDtongehsirooiewlfDhe\n",
      "uhia h, ehle ttirh oSleo. d.e  pafotwtrAl?\n",
      "aytg’tIeAtmcrefwnI  efo lgSamoooo  lEeeo pdh\n",
      "Bogbta\n",
      "togtaS oCiw\n",
      "EepwehtEIgCslreatrbgomecu seothiliseAeh MSilW uHlr  .arma\n",
      "dTIh, hbr ,ye adn h natsileiam a  NarWnnrbn  eYhta u M.rslbc oee C a  yIWioaoya s  ’ F_yLee\n",
      "fwl itc !v’g dAo\n",
      "b,  —lefrsynmr crg,aro _mw_mtscwsn tn -Usocaoinoaat\n",
      "oo Ebenn sd\n",
      "nhoeos r l rruhrekaepbrU\n",
      "t Us r sheI ee  .Gyiaecoo tT.UahrLwO\n",
      "l.Bh m n waEtitoeue nhhCbfrmteer igrdltrstrna,Asn ah\n",
      "x   tr\n",
      "oe Ahteyi\n",
      " l iBa e’fng d\n",
      "r iitsGsoawOfaaee rolsunolstsc,.Is fu’hhrsr ri rr om de \n",
      " hi r ml rEeAe—\n",
      "hltsde hmoouaau\n",
      "s\n",
      "ooh,le.oelhsspAoef\n",
      "t i  nenu’  Cvroelgs  m he btt\n",
      "Ehrieynasslt \n",
      "nn t nlf . hhSKset Hrooalss,GiAV m U. br ee\n",
      "eehubsEctn nf m.?eissTdrinaTe tnlyhaonteayhdeAnwouoM o \n",
      "oartfaSone mtn n tcaeshhtiefpeIe ru\n",
      "elna t\n",
      " lnsf saM\n",
      "w fbJnw \n",
      "\n",
      "goe Sph \n"
     ]
    }
   ],
   "source": [
    "\"character frequency generation\"\n",
    "import random\n",
    "print(\"\".join(random.choices(population=char,weights=counts,k=1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TextIO\n",
    "import random\n",
    "def read_chunk(file:TextIO,chunk_size:int=1024)->str:\n",
    "    while True:\n",
    "        str_chunk = file.read(chunk_size)\n",
    "        if not str_chunk:\n",
    "            break\n",
    "        yield str_chunk\n",
    "\n",
    "#now develop some conditional memory\n",
    "#a small class will help us with book keeping\n",
    "class MarkovChain():\n",
    "    EOD=\"\\u0000\"\n",
    "    def __init__(self,window_size:int=1) -> None:\n",
    "        assert window_size>0\n",
    "        self._window_size=window_size\n",
    "        self._memory={}\n",
    "        self._current_buffer=[str(0x0) for _ in range(window_size+1)] #bootstrap with null chars\n",
    "        self._generate_buffer=\"\"\n",
    "        for window in range(window_size+1):\n",
    "            self._memory[window]={}\n",
    "\n",
    "    def update(self,character:str)->None:\n",
    "        assert len(character)==1\n",
    "        self._current_buffer.append(character)\n",
    "        self._current_buffer.pop(0)\n",
    "        for i in range(1,self._window_size+2):\n",
    "            self.update_item(\"\".join(self._current_buffer[-i:]))\n",
    "\n",
    "\n",
    "    def update_item(self,string:str)->None:\n",
    "        window_index=len(string)-1\n",
    "        if string in self._memory[window_index]:\n",
    "            self._memory[window_index][string]+=1\n",
    "        else:\n",
    "            self._memory[window_index][string]=1\n",
    "\n",
    "    def finish_training(self)->None:\n",
    "        \"\"\"used for end of document signal\"\"\"\n",
    "        self.update(self.EOD)\n",
    "\n",
    "    def _next_char(self)->str:\n",
    "        base_count = self._memory[len(self._generate_buffer)-1].get(self._generate_buffer)\n",
    "\n",
    "\n",
    "        if not base_count:\n",
    "            raise ValueError(\"i've never seen this before :(\")\n",
    "\n",
    "        population = []\n",
    "        counts=[]\n",
    "\n",
    "        for string,count in self._memory[len(self._generate_buffer)].items():\n",
    "            if string[0:len(self._generate_buffer)]==self._generate_buffer:\n",
    "                population.append(string)\n",
    "                counts.append(count)\n",
    "\n",
    "\n",
    "        if sum(counts)!=base_count:\n",
    "            error_msg=f\"\"\" COUNTS DON'T MATCH\n",
    "            buffer={self._generate_buffer}\n",
    "            count={base_count}\n",
    "            count_array={counts}, sum={sum(counts)}\n",
    "            pop={population}\n",
    "            \"\"\"\n",
    "            raise RuntimeError(error_msg)\n",
    "        return random.choices(population=population,weights=counts,k=1)[0][-1:]\n",
    "\n",
    "    def generate_string(self,init:str,n=500)->str:\n",
    "        self._generate_buffer=init[-self._window_size:]\n",
    "\n",
    "        for _ in range(n):\n",
    "            next_char = self._next_char()\n",
    "            if next_char==self.EOD:\n",
    "                break\n",
    "            self._generate_buffer = (self._generate_buffer+next_char)[-self._window_size:]\n",
    "            yield next_char\n",
    "\n",
    "\n",
    "\n",
    "mc = MarkovChain(window_size=7)\n",
    "\n",
    "with open(\"resources/shakespeare.txt\", mode=\"r\", encoding=\"utf-8\") as file_obj:\n",
    "    for str_chunk in read_chunk(file_obj):\n",
    "        for char in str_chunk:\n",
    "            mc.update(char)\n",
    "    mc.finish_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEROWNE.\n",
      "I warrant may not an hour,\n",
      "We are fit you have handsome work, you’d carry out for proof of arms be born, and Timandra.\n",
      "\n",
      " Enter Mistress Page for it. Honour.\n",
      "\n",
      "ANGELO.\n",
      "My lord is bright than falls like a hidden, hemm’d with you.\n",
      "Are you well, thou didst intends;\n",
      "And it grant than wives,\n",
      "This griefs the hangman of an eye of anything thither—\n",
      "\n",
      " Enter Don Pedro is reeling still and waddled all,\n",
      "The one word.\n",
      "Boyet, and treble woe!\n",
      "Come, Margaret was the sighed as my friends that threatens; men that good years,\n",
      "    And therefore? O me! What, am I constant, lovely said to me, you rogue.\n",
      "\n",
      "HAMLET.\n",
      "I am your sight on.\n",
      "\n",
      "JULIA.\n",
      "And yet the face by day\n",
      "Where lock’d in Kent._]\n",
      "\n",
      "HELENA.\n",
      "Ay, but bastard and my nipple\n",
      "Of the wit in the magnanimous and thee\n",
      "Once more, I beseech you—\n",
      "Chiefly for a light that was thy wit o’both sides.\n",
      "Farewell. If thou ever be seen then pardonner aucun prisoner will I be gentle wealth\n",
      "enough to be one of ’em\n",
      "I knew you are!\n",
      "These are thee a hundred and his friend \n"
     ]
    }
   ],
   "source": [
    "init_string = \"B\"\n",
    "print(f'{init_string}{\"\".join([char for char in  mc.generate_string(init_string,1000)])}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65450\n"
     ]
    }
   ],
   "source": [
    "with open(\"test.db\", mode=\"r+\", encoding=\"utf-8\") as file_obj:\n",
    "    with mmap.mmap(file_obj.fileno(), length=0, access=mmap.ACCESS_WRITE) as mmap_obj:\n",
    "        print(int.from_bytes(mmap_obj[500:504],signed=False))\n",
    "#        mmap_obj[500:504]=0xFFAA.to_bytes(4,signed=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "relu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
